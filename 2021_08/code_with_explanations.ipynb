{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ceb67e5",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4753fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d988c",
   "metadata": {},
   "source": [
    "# 1. Get the data\n",
    "\n",
    "## 1.1 Download the data\n",
    "In order to obtain the data I use the kaggle API, in the following link there is a guide to initial the kaggle API - [kaggle API](https://github.com/Kaggle/kaggle-api).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ab6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Get the data with kaggle API\n",
    "\"\"\"\n",
    "\n",
    "filename: str = 'tabular-playground-series-aug-2021'\n",
    "    \n",
    "def get_data_from_kaggle_with_API(filename):\n",
    "    \"\"\"\n",
    "    this function checks if you have downloaded the data to the current path.\n",
    "    If yes it checks if the data is unzipped and the 'test.csv' file exists.\n",
    "    If no it unzips the downloaded zip data and then delete the zipped file from the current path \n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filename + '.zip') and not os.path.isfile('test.csv'):\n",
    "        os.system(\"kaggle competitions download -c \" + filename)\n",
    "\n",
    "    if not os.path.isfile('test.csv') and os.path.isfile(filename + '.zip'):\n",
    "        os.system('unzip ' + filename + '.zip')\n",
    "        os.system('rm tabular-playground-series-aug-2021.zip')\n",
    "\n",
    "    if os.path.isfile('test.csv') and os.path.isfile(filename + '.zip'):\n",
    "        os.system('rm tabular-playground-series-aug-2021.zip')\n",
    "\n",
    "get_data_from_kaggle_with_API(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376724b",
   "metadata": {},
   "source": [
    "## 1.2 Load the data to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e96a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = pd.read_csv('train.csv')  # read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43180d2",
   "metadata": {},
   "source": [
    "## 1.3 Split to features(X) and lable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b472983",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train: np.ndarray = df_train.values\n",
    "X: np.ndarray = data_train[:, 1:-1]\n",
    "y: np.ndarray = data_train[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=217)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ff4f8",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eee04e",
   "metadata": {},
   "source": [
    "## 2.1 features type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4fe020ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 102 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   f0      float64\n",
      " 2   f1      int64  \n",
      " 3   f2      float64\n",
      " 4   f3      float64\n",
      " 5   f4      float64\n",
      " 6   f5      float64\n",
      " 7   f6      float64\n",
      " 8   f7      float64\n",
      " 9   f8      float64\n",
      " 10  f9      float64\n",
      " 11  f10     float64\n",
      " 12  f11     float64\n",
      " 13  f12     float64\n",
      " 14  f13     float64\n",
      " 15  f14     float64\n",
      " 16  f15     float64\n",
      " 17  f16     int64  \n",
      " 18  f17     float64\n",
      " 19  f18     float64\n",
      " 20  f19     float64\n",
      " 21  f20     float64\n",
      " 22  f21     float64\n",
      " 23  f22     float64\n",
      " 24  f23     float64\n",
      " 25  f24     float64\n",
      " 26  f25     float64\n",
      " 27  f26     float64\n",
      " 28  f27     int64  \n",
      " 29  f28     float64\n",
      " 30  f29     float64\n",
      " 31  f30     float64\n",
      " 32  f31     float64\n",
      " 33  f32     float64\n",
      " 34  f33     float64\n",
      " 35  f34     float64\n",
      " 36  f35     float64\n",
      " 37  f36     float64\n",
      " 38  f37     float64\n",
      " 39  f38     float64\n",
      " 40  f39     float64\n",
      " 41  f40     float64\n",
      " 42  f41     float64\n",
      " 43  f42     float64\n",
      " 44  f43     float64\n",
      " 45  f44     float64\n",
      " 46  f45     float64\n",
      " 47  f46     float64\n",
      " 48  f47     float64\n",
      " 49  f48     float64\n",
      " 50  f49     float64\n",
      " 51  f50     float64\n",
      " 52  f51     float64\n",
      " 53  f52     float64\n",
      " 54  f53     float64\n",
      " 55  f54     float64\n",
      " 56  f55     int64  \n",
      " 57  f56     float64\n",
      " 58  f57     float64\n",
      " 59  f58     float64\n",
      " 60  f59     float64\n",
      " 61  f60     float64\n",
      " 62  f61     float64\n",
      " 63  f62     float64\n",
      " 64  f63     float64\n",
      " 65  f64     float64\n",
      " 66  f65     float64\n",
      " 67  f66     float64\n",
      " 68  f67     float64\n",
      " 69  f68     float64\n",
      " 70  f69     float64\n",
      " 71  f70     float64\n",
      " 72  f71     float64\n",
      " 73  f72     float64\n",
      " 74  f73     float64\n",
      " 75  f74     float64\n",
      " 76  f75     float64\n",
      " 77  f76     float64\n",
      " 78  f77     float64\n",
      " 79  f78     float64\n",
      " 80  f79     float64\n",
      " 81  f80     float64\n",
      " 82  f81     float64\n",
      " 83  f82     float64\n",
      " 84  f83     float64\n",
      " 85  f84     float64\n",
      " 86  f85     float64\n",
      " 87  f86     int64  \n",
      " 88  f87     float64\n",
      " 89  f88     float64\n",
      " 90  f89     float64\n",
      " 91  f90     float64\n",
      " 92  f91     float64\n",
      " 93  f92     float64\n",
      " 94  f93     float64\n",
      " 95  f94     float64\n",
      " 96  f95     float64\n",
      " 97  f96     float64\n",
      " 98  f97     float64\n",
      " 99  f98     float64\n",
      " 100 f99     float64\n",
      " 101 loss    int64  \n",
      "dtypes: float64(95), int64(7)\n",
      "memory usage: 194.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info(verbose = True, null_counts = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa85447",
   "metadata": {},
   "source": [
    "All the features are numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa5be1",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f68e434b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eeadff",
   "metadata": {},
   "source": [
    "That is unpopular way to check NaN values but it work fast.\n",
    "\n",
    "There aren't any NaN Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eec008",
   "metadata": {},
   "source": [
    "## 2.3 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daba2ad",
   "metadata": {},
   "source": [
    "All the features are continues so I checked pearson correaltion \n",
    "\n",
    "The pearson correlation between $X_i$ and $X_j$ is:\n",
    "\n",
    "$ \\rho_{i,j} = \\frac{\\sum(X_i-\\bar{X_i})(X_j-\\bar{X_j})}{\\sqrt{\\sum(X_i-\\bar{X_i})^2}\\sqrt{\\sum(X_j-\\bar{X_j})^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1391b34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_train.iloc[:,1:-1].corr(method='pearson')\n",
    "\n",
    "any(abs(corr.where(corr > 0.2)).sum() > 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0557d01",
   "metadata": {},
   "source": [
    "There aren't any two features s.t $ |\\rho_{i,j}| > 0.2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b0449",
   "metadata": {},
   "source": [
    "# 3. Models\n",
    "\n",
    "In this section I'll addapt 2 machine learning algorithms:\n",
    "\n",
    "1) Random forest\n",
    "\n",
    "2) Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6d828",
   "metadata": {},
   "source": [
    "## 3.1 Random forest\n",
    "\n",
    "In this sub section I'll create a grid of hyperparameters and use $4Fold-CV$ to optimize/tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a28210ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Random Forest Model\n",
    "\"\"\"\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start=3, stop=99, num=10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10]\n",
    "\n",
    "\n",
    "\n",
    "# Create the grid\n",
    "grid = {'max_features': max_features,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        }\n",
    "\n",
    "# define model\n",
    "rf = RandomForestRegressor()\n",
    "# define search\n",
    "grid_search_rf = GridSearchCV(estimator=rf,\n",
    "                            param_grid=grid,\n",
    "                            scoring='neg_root_mean_squared_error',\n",
    "                            cv=3,\n",
    "                            verbose=2,\n",
    "                            n_jobs=-1)\n",
    "# perform the search\n",
    "results = grid_search_rf.fit(X_train, y_train)\n",
    "\"\"\"\n",
    " Get the paramters that gives the best RMSE\n",
    "\"\"\"\n",
    "\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "loss_rf = best_model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac9c23",
   "metadata": {},
   "source": [
    "# 3.2 Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a75e5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orlevi/dev/virtual_envs/ml_env/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.2632e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/orlevi/dev/virtual_envs/ml_env/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.2632e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "grid = dict()\n",
    "grid['alpha'] = [x for x in np.linspace(start=0, stop=4, num=100)]\n",
    "\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge,\n",
    "                            param_grid=grid,\n",
    "                            scoring='neg_root_mean_squared_error',\n",
    "                            cv=3,\n",
    "                            verbose=2,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "results = grid_search_ridge.fit(X_train, y_train)\n",
    "best_model_ridge = grid_search_ridge.best_estimator_\n",
    "best_model_ridge.fit(X_train, y_train)\n",
    "\n",
    "loss_ridge = best_model_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e62371",
   "metadata": {},
   "source": [
    "# 4. Models evaluation\n",
    "In this section I will evaluate each model with some different scores.\n",
    "\n",
    "And then I'll choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "746c10c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE:  63.065875557639544\n",
      "Random Forest R2:  -71.3535399282651\n",
      "ridge MSE:  62.35700825673176\n",
      "ridge R2:  -79.38128478119711\n"
     ]
    }
   ],
   "source": [
    "MSE_rf =  mean_squared_error(loss_rf,y_test)\n",
    "R2_rf = r2_score(loss_rf,y_test)\n",
    "\n",
    "MSE_ridge = mean_squared_error(loss_ridge,y_test)\n",
    "R2_ridge = r2_score(loss_ridge,y_test)\n",
    "\n",
    "print(\"Random Forest MSE: \", MSE_rf)\n",
    "print(\"Random Forest R2: \", R2_rf)\n",
    "\n",
    "print(\"ridge MSE: \", MSE_ridge)\n",
    "print(\"ridge R2: \", R2_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf98a87",
   "metadata": {},
   "source": [
    "# 5. Provide predictions with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "531d09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions to test set\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_test: pd.DataFrame = pd.read_csv('test.csv')  # read data\n",
    "\n",
    "data_test: np.ndarray = df_test.values\n",
    "X_test: np.ndarray = data_test[:, 1:]  \n",
    "    \n",
    "loss_ridge = best_model_ridge.predict(X_test)\n",
    "prediction: pd.DataFrame = pd.DataFrame({\n",
    "    'id': df_test.values[:, 0].astype(int),\n",
    "    'loss': loss_ridge\n",
    "})\n",
    "\n",
    "prediction.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a450be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>7.353264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>5.366966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.727362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>6.621150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.402665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  7.353264\n",
       "1  250001  5.366966\n",
       "2  250002  7.727362\n",
       "3  250003  6.621150\n",
       "4  250004  7.402665"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50bb91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
